{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1afadcd04d794dd4a293c3fb0f05996e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29d6345fd69042399e73c8b303b691ec",
              "IPY_MODEL_5c0a54f02b40456a94c977ce88885c12",
              "IPY_MODEL_e3b26ed73798411abe7d5d7b89d595a9"
            ],
            "layout": "IPY_MODEL_01bafb631ddc475fbbec9b5a5c7d22fd"
          }
        },
        "29d6345fd69042399e73c8b303b691ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75eb2894a2e0469badd49a7ffbdc50bf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bb1b8d0692ba4a0d891bf94007abad45",
            "value": "README.md:‚Äá"
          }
        },
        "5c0a54f02b40456a94c977ce88885c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eee31a68b284574aaf217ee2a94fa0d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b628fafd2e0a476ca88be171ce00c87d",
            "value": 1
          }
        },
        "e3b26ed73798411abe7d5d7b89d595a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be51f2f543e4591bd85558fb030ea88",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_57b0dba066774c59a727ed492e32df66",
            "value": "‚Äá3.53k/?‚Äá[00:00&lt;00:00,‚Äá76.8kB/s]"
          }
        },
        "01bafb631ddc475fbbec9b5a5c7d22fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75eb2894a2e0469badd49a7ffbdc50bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb1b8d0692ba4a0d891bf94007abad45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eee31a68b284574aaf217ee2a94fa0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b628fafd2e0a476ca88be171ce00c87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5be51f2f543e4591bd85558fb030ea88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b0dba066774c59a727ed492e32df66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab58b09ea904468fb6cfd4863856ff9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48cb10d56eac4aa5b264f64dffaecbb3",
              "IPY_MODEL_925aa648832d4a23b20e60ff9e9817a7",
              "IPY_MODEL_de95752fe53e4fd9a05aca85c5a1ed7e"
            ],
            "layout": "IPY_MODEL_2b579af528f1446da3f4adf76fd1e61e"
          }
        },
        "48cb10d56eac4aa5b264f64dffaecbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68907d03f4a2465e92c9f2d3c8de5689",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ef0f75b077e748e7b19df9a0d7651960",
            "value": "data/train-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "925aa648832d4a23b20e60ff9e9817a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0228d11dbab348c3947c402af946a977",
            "max": 352401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de93b31657894397b719edc49cca6f7a",
            "value": 352401
          }
        },
        "de95752fe53e4fd9a05aca85c5a1ed7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0f41637c32469b8af0a9fb3cfe2c8b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fc41c242ab5a482e909b0af7f3465c6f",
            "value": "‚Äá352k/352k‚Äá[00:00&lt;00:00,‚Äá476kB/s]"
          }
        },
        "2b579af528f1446da3f4adf76fd1e61e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68907d03f4a2465e92c9f2d3c8de5689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef0f75b077e748e7b19df9a0d7651960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0228d11dbab348c3947c402af946a977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de93b31657894397b719edc49cca6f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea0f41637c32469b8af0a9fb3cfe2c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc41c242ab5a482e909b0af7f3465c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "634c235af44a43dab21fcb5aa6b6c78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_864899e2ddf5455b8e115e3d7e8ded32",
              "IPY_MODEL_16ab6166dd304fceb9d502e51c7a4851",
              "IPY_MODEL_277ed4a8a37f474dae507607d079223c"
            ],
            "layout": "IPY_MODEL_1037efbe2eb842c5a1a1f91557e45643"
          }
        },
        "864899e2ddf5455b8e115e3d7e8ded32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d77f1704ef0d41249065a05a49f4060f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8ffab9607d574588b69812052e8e1b8e",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "16ab6166dd304fceb9d502e51c7a4851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_164359465aad4e70a6507ed0a4d65a1b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1163b81ad9a4cefac1c955a52d61de9",
            "value": 100
          }
        },
        "277ed4a8a37f474dae507607d079223c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f40c22d1d371480690cf9506ec0e7aea",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_28e5abb42a3549aeb64e0f0ccc7ca062",
            "value": "‚Äá100/100‚Äá[00:00&lt;00:00,‚Äá1058.12‚Äáexamples/s]"
          }
        },
        "1037efbe2eb842c5a1a1f91557e45643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d77f1704ef0d41249065a05a49f4060f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ffab9607d574588b69812052e8e1b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "164359465aad4e70a6507ed0a4d65a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1163b81ad9a4cefac1c955a52d61de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f40c22d1d371480690cf9506ec0e7aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e5abb42a3549aeb64e0f0ccc7ca062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ochiait/Bridge-to-Practice-Course/blob/master/llm_jp_3_1_1_8b_ja_structured_train_n95_rev2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#00_data-load"
      ],
      "metadata": {
        "id": "_gqmOJyd8ms1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, math\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# --- „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊåáÂÆö ---\n",
        "DATASET_REPO = \"morizon/TCGA_Reports_ja_structured-filtered\"\n",
        "\n",
        "# --- „Éá„Éº„Çø„É≠„Éº„Éâ ---\n",
        "ds_all = load_dataset(DATASET_REPO)\n",
        "raw_ds = ds_all[\"train\"]\n",
        "\n",
        "total_len = len(raw_ds)\n",
        "train_size = math.floor(total_len * 0.95)\n",
        "raw_ds_train = raw_ds.select(range(0, train_size))\n",
        "raw_ds_eval = raw_ds.select(range(train_size, total_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "1afadcd04d794dd4a293c3fb0f05996e",
            "29d6345fd69042399e73c8b303b691ec",
            "5c0a54f02b40456a94c977ce88885c12",
            "e3b26ed73798411abe7d5d7b89d595a9",
            "01bafb631ddc475fbbec9b5a5c7d22fd",
            "75eb2894a2e0469badd49a7ffbdc50bf",
            "bb1b8d0692ba4a0d891bf94007abad45",
            "5eee31a68b284574aaf217ee2a94fa0d",
            "b628fafd2e0a476ca88be171ce00c87d",
            "5be51f2f543e4591bd85558fb030ea88",
            "57b0dba066774c59a727ed492e32df66",
            "ab58b09ea904468fb6cfd4863856ff9a",
            "48cb10d56eac4aa5b264f64dffaecbb3",
            "925aa648832d4a23b20e60ff9e9817a7",
            "de95752fe53e4fd9a05aca85c5a1ed7e",
            "2b579af528f1446da3f4adf76fd1e61e",
            "68907d03f4a2465e92c9f2d3c8de5689",
            "ef0f75b077e748e7b19df9a0d7651960",
            "0228d11dbab348c3947c402af946a977",
            "de93b31657894397b719edc49cca6f7a",
            "ea0f41637c32469b8af0a9fb3cfe2c8b",
            "fc41c242ab5a482e909b0af7f3465c6f",
            "634c235af44a43dab21fcb5aa6b6c78a",
            "864899e2ddf5455b8e115e3d7e8ded32",
            "16ab6166dd304fceb9d502e51c7a4851",
            "277ed4a8a37f474dae507607d079223c",
            "1037efbe2eb842c5a1a1f91557e45643",
            "d77f1704ef0d41249065a05a49f4060f",
            "8ffab9607d574588b69812052e8e1b8e",
            "164359465aad4e70a6507ed0a4d65a1b",
            "e1163b81ad9a4cefac1c955a52d61de9",
            "f40c22d1d371480690cf9506ec0e7aea",
            "28e5abb42a3549aeb64e0f0ccc7ca062"
          ]
        },
        "id": "wlK_3puzHhm4",
        "outputId": "9f84e7da-5005-46f5-913f-4d0b4dd629a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1afadcd04d794dd4a293c3fb0f05996e"
            }
          },
          "metadata": {
              "widgets": {
                  "state": {}
              }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/352k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab58b09ea904468fb6cfd4863856ff9a"
            }
          },
          "metadata": {
              "widgets": {
                  "state": {}
              }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "634c235af44a43dab21fcb5aa6b6c78a"
            }
          },
          "metadata": {
              "widgets": {
                  "state": {}
              }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#01_inference"
      ],
      "metadata": {
        "id": "pG1jdCGp7VrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Êé®Ë´ñÊù°‰ª∂(Â≠¶ÁøíÂâçÂæå„ÅßÂÖ±ÈÄöÂåñ)\n",
        "GEN_KWARGS = dict(\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    top_p=0.95,\n",
        "    temperature=0.7,\n",
        "    repetition_penalty=1.05,\n",
        ")"
      ],
      "metadata": {
        "id": "F5lDJsLtm6Oj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYR1ygb8jCTN"
      },
      "outputs": [],
      "source": [
        "# @title LLM-jp-3.1 Êé®Ë´ñÁî®„ÅÆ„É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\n",
        "!pip install torch>=2.3.0 transformers>=4.40.1 tokenizers>=0.19.1 accelerate>=0.29.3 flash-attn>=2.5.8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LLM-jp-3.1 Pre-trained Models\n",
        "####llm-jp/llm-jp-3.1-1.8b"
      ],
      "metadata": {
        "id": "1sfIihOGpC-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_model_1=\"llm-jp/llm-jp-3.1-1.8b\""
      ],
      "metadata": {
        "id": "Sor2FD7sJL_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(inference_model_1)\n",
        "model = AutoModelForCausalLM.from_pretrained(inference_model_1, device_map=\"auto\", torch_dtype=None)"
      ],
      "metadata": {
        "id": "Gni6xK9_pI3r",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.dtype)\n",
        "print(next(model.parameters()).dtype)"
      ],
      "metadata": {
        "id": "znlMd_5p9YCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# ====================================================\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó1Ôºö„Éó„É≠„É≥„Éó„ÉàÊßãÁØâ„ÅÆÊ∫ñÂÇôÔºà‚òÖ„Åì„Åì„ÇíËøΩÂä†Ôºâ ‚ñº‚ñº‚ñº\n",
        "# ====================================================\n",
        "SCHEMA_STR = (\n",
        "    '{ \"ËáìÂô®\": \"\", \"Êé°ÂèñÊñπÊ≥ï\": \"\", \"Ë®∫Êñ≠\": \"\", \"ÂàÜÂåñÂ∫¶\": \"\", '\n",
        "    '\"ÁóÖÊúü\": \"\", \"ËÖ´ÁòçÂæÑ\": \"\", \"Êµ∏ÊΩ§ÁØÑÂõ≤\": \"\", \"Êñ≠Á´Ø\": \"\", \"„Åù„ÅÆ‰ªñÊâÄË¶ã\": \"\" }'\n",
        ")\n",
        "\n",
        "def build_prompt(text):\n",
        "    return (\n",
        "        \"#ÊåáÁ§∫\\n\"\n",
        "        \"Ê¨°„ÅÆÊñáÁ´†„Çí‰ª•‰∏ã„ÅÆJSONÂΩ¢Âºè„Å´ÊßãÈÄ†Âåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\n\"\n",
        "        f\"{SCHEMA_STR}\\n\\n\"\n",
        "        \"#ÊäΩÂá∫ÂØæË±°\\n\"\n",
        "        f\"{text}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "9YfZz8P54P2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó2ÔºöÊé®Ë´ñ„Åó„Å¶‰øùÂ≠òÔºà‚òÖ„Åì„Åì„Çí‰øÆÊ≠£Ôºâ ‚ñº‚ñº‚ñº\n",
        "# ====================================================\n",
        "results = []\n",
        "\n",
        "# raw_ds_eval „ÅÆ„Åô„Åπ„Å¶„ÅÆ„Çµ„É≥„Éó„É´„Å´ÂØæ„Åó„Å¶„É´„Éº„Éó„ÇíÂÆüË°å\n",
        "for i, sample in enumerate(raw_ds_eval):\n",
        "    # 1. „Éá„Éº„Çø„Çª„ÉÉ„Éà„Åã„ÇâÂÖÉ„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÇíÂèñÂæó\n",
        "    original_question = sample[\"question_ja\"]\n",
        "\n",
        "    # 2. build_promptÈñ¢Êï∞„Çí‰Ωø„Å£„Å¶„Éó„É≠„É≥„Éó„Éà„ÇíÊßãÁØâÔºà‚òÖËøΩÂä†Ôºâ\n",
        "    prompt_text = build_prompt(original_question)\n",
        "\n",
        "    # 3. ÊßãÁØâ„Åó„Åü„Éó„É≠„É≥„Éó„Éà„Çí„Éà„Éº„ÇØ„Éä„Ç§„Ç∫Ôºà‚òÖÂÖ•ÂäõÂ§âÊï∞„ÇíÂ§âÊõ¥Ôºâ\n",
        "    tokenized_input = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # 4. Êé®Ë´ñ„ÇíÂÆüË°å\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(tokenized_input, **GEN_KWARGS)[0]\n",
        "\n",
        "    # 5. ÁîüÊàê„Åï„Çå„ÅüÈÉ®ÂàÜ„Å†„Åë„Çí„Éá„Ç≥„Éº„Éâ\n",
        "    input_token_len = len(tokenized_input[0])\n",
        "    generated_tokens = output[input_token_len:]\n",
        "    output_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    # 6. ÁµêÊûú„Çí„É™„Çπ„Éà„Å´‰øùÂ≠ò\n",
        "    #    \"input\"„Å´„ÅØÂÖÉ„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„Çí‰øùÂ≠ò„Åó„Å¶„ÄÅ‰Ωï„ÇíÂÖ•Âäõ„Åó„Åü„Åã„Çè„Åã„Çã„Çà„ÅÜ„Å´„Åô„Çã\n",
        "    results.append({\n",
        "        \"input\": original_question,\n",
        "        \"model_output\": output_text.strip()\n",
        "    })\n",
        "\n",
        "    print(f\"--- „Çµ„É≥„Éó„É´ {i} ÂÆå‰∫Ü ---\") # ÈÄ≤ÊçóË°®Á§∫Ôºà‰ªªÊÑèÔºâ\n",
        "\n",
        "# ====================================================\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó3Ôºö„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠òÔºà„Åì„Åì„ÅØÂ§âÊõ¥„Å™„ÅóÔºâ ‚ñº‚ñº‚ñº\n",
        "# ====================================================\n",
        "# --- „Éï„Ç°„Ç§„É´Âêç„Çí„É¢„Éá„É´Âêç„Åã„ÇâËá™ÂãïÁîüÊàê ---\n",
        "# ‰æã: \"llm-jp/llm-jp-3.1-1.8b\" ‚Üí \"llm-jp-3.1-1.8b\"\n",
        "modelname_1 = inference_model_1.split(\"/\")[-1]\n",
        "output_filename_1 = f\"eval_result_{modelname_1}.json\"\n",
        "\n",
        "# --- JSON„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò ---\n",
        "with open(output_filename_1, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Êé®Ë´ñÁµêÊûú„Çí {output_filename_1} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü„ÄÇ\")"
      ],
      "metadata": {
        "id": "mZMB2Gap4MzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Êé®Ë´ñÁµêÊûú„Çí DataFrame „Å´Â§âÊèõ ---\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# --- Ë°®Á§∫Ë®≠ÂÆö ---\n",
        "pd.set_option('display.max_colwidth', None)   # Èï∑Êñá„ÇíÁúÅÁï•„Åõ„ÅöË°®Á§∫\n",
        "pd.set_option('display.max_rows', 100)        # Ë°®Á§∫Ë°åÊï∞„ÇíË™øÊï¥ÔºàÂøÖË¶Å„Å™„ÇâÂ¢ó„ÇÑ„ÅôÔºâ\n",
        "pd.set_option('display.width', None)          # Ê®™ÂπÖ„ÇíËá™ÂãïË™øÊï¥\n",
        "\n",
        "# --- Colab‰∏ä„Åß„Çπ„ÇØ„É≠„Éº„É´‰ªò„ÅçHTMLË°®Á§∫ ---\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# È´ò„Åï„ÉªÂπÖ„ÇíÊåáÂÆö„Åó„Å¶„Çπ„ÇØ„É≠„Éº„É´ÂèØËÉΩ„Å´\n",
        "scrollable_html = df_results.to_html(escape=False)\n",
        "display(HTML(f'<div style=\"max-height:600px; overflow-y:auto; border:1px solid #ccc;\">{scrollable_html}</div>'))\n",
        "\n",
        "# --- ‰øùÂ≠ò„Éï„Ç°„Ç§„É´Á¢∫Ë™ç„É°„ÉÉ„Çª„Éº„Ç∏ ---\n",
        "print(f\"‚úÖ Êé®Ë´ñÁµêÊûú„Çí {output_filename_1} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "print(\"üëá ‰∏ã„ÅÆË°®„ÅßÂÖ®Êñá„Çπ„ÇØ„É≠„Éº„É´Ë°®Á§∫„Åß„Åç„Åæ„Åô„ÄÇÂøÖË¶Å„Å´Âøú„Åò„Å¶ df_results „Çí Colab „ÅÆ Data „Çø„Éñ„ÅßÈñã„ÅÑ„Å¶„ÇÇOK„ÄÇ\")"
      ],
      "metadata": {
        "id": "j4c9LYou0XBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LLM-jp-3.1 Fine-tuned Models\n",
        "####llm-jp/llm-jp-3.1-1.8b-instruct4\n",
        "####llm-jp/llm-jp-3.1-1.8„ÅÆÊé®Ë´ñ„ÇíÂÆüË°å„Åó„ÅüÂ†¥Âêà„ÅØ„ÄÅ„Åã„Å™„Çâ„Åö„É©„É≥„Çø„Ç§„É†„ÇíÊé•Á∂öËß£Èô§„Åó„Å¶ÂâäÈô§„ÇíÂÆüÊñΩ„Åó„ÄÅ‰ª•‰∏ã„ÅÆ„Çª„É´„ÇíÂÆüË°å„Åè„Å†„Åï„ÅÑ„ÄÇ"
      ],
      "metadata": {
        "id": "t4knLJwxon68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, math\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# --- „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊåáÂÆö ---\n",
        "DATASET_REPO = \"morizon/TCGA_Reports_ja_structured-filtered\"\n",
        "\n",
        "# --- „Éá„Éº„Çø„É≠„Éº„Éâ ---\n",
        "ds_all = load_dataset(DATASET_REPO)\n",
        "raw_ds = ds_all[\"train\"]\n",
        "\n",
        "total_len = len(raw_ds)\n",
        "train_size = math.floor(total_len * 0.95)\n",
        "raw_ds_train = raw_ds.select(range(0, train_size))\n",
        "raw_ds_eval = raw_ds.select(range(train_size, total_len))"
      ],
      "metadata": {
        "id": "mvTwGI8B-X-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Êé®Ë´ñÊù°‰ª∂(Â≠¶ÁøíÂâçÂæå„ÅßÂÖ±ÈÄöÂåñ)\n",
        "GEN_KWARGS = dict(\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    top_p=0.95,\n",
        "    temperature=0.7,\n",
        "    repetition_penalty=1.05,\n",
        ")"
      ],
      "metadata": {
        "id": "iZiR7449-kkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title LLM-jp-3.1 Êé®Ë´ñÁî®„ÅÆ„É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\n",
        "!pip install torch>=2.3.0 transformers>=4.40.1 tokenizers>=0.19.1 accelerate>=0.29.3 flash-attn>=2.5.8"
      ],
      "metadata": {
        "id": "y9Mhg8Gd-yiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_model_2=\"llm-jp/llm-jp-3.1-1.8b-instruct4\""
      ],
      "metadata": {
        "id": "iTbbVGiC66f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(inference_model_2)\n",
        "model = AutoModelForCausalLM.from_pretrained(inference_model_2, device_map=\"auto\", torch_dtype=None)"
      ],
      "metadata": {
        "id": "Pu3w09d2kQGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch # torch.no_grad() „ÅÆ„Åü„ÇÅ„Å´„Ç§„É≥„Éù„Éº„Éà\n",
        "\n",
        "# ====================================================\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó1Ôºö„Éó„É≠„É≥„Éó„Éà„ÅÆÂÖÉ„Å®„Å™„Çã„Çπ„Ç≠„Éº„Éû„ÇíÂÆöÁæ©ÔºàÂ§âÊõ¥„Å™„ÅóÔºâ ‚ñº‚ñº‚ñº\n",
        "# ====================================================\n",
        "SCHEMA_STR = (\n",
        "    '{ \"ËáìÂô®\": \"\", \"Êé°ÂèñÊñπÊ≥ï\": \"\", \"Ë®∫Êñ≠\": \"\", \"ÂàÜÂåñÂ∫¶\": \"\", '\n",
        "    '\"ÁóÖÊúü\": \"\", \"ËÖ´ÁòçÂæÑ\": \"\", \"Êµ∏ÊΩ§ÁØÑÂõ≤\": \"\", \"Êñ≠Á´Ø\": \"\", \"„Åù„ÅÆ‰ªñÊâÄË¶ã\": \"\" }'\n",
        ")\n",
        "\n",
        "# ====================================================\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó2ÔºöÊé®Ë´ñ„Åó„Å¶‰øùÂ≠òÔºà‚òÖ„Åì„Åì„ÇíÂÖ®Èù¢ÁöÑ„Å´‰øÆÊ≠£Ôºâ ‚ñº‚ñº‚ñº\n",
        "# ====================================================\n",
        "results = []\n",
        "\n",
        "# „ÄêÊé®Â•®„ÄëË≠¶Âëä„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÊäëÂà∂„Åó„ÄÅÂÆâÂÆö„Åó„ÅüÊé®Ë´ñ„ÇíË°å„ÅÜ„Åü„ÇÅ„ÅÆË®≠ÂÆö\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# raw_ds_eval „ÅÆ„Åô„Åπ„Å¶„ÅÆ„Çµ„É≥„Éó„É´„Å´ÂØæ„Åó„Å¶„É´„Éº„Éó„ÇíÂÆüË°å\n",
        "for i, sample in enumerate(raw_ds_eval):\n",
        "    # 1. „Éá„Éº„Çø„Çª„ÉÉ„Éà„Åã„ÇâÂÖÉ„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÇíÂèñÂæó\n",
        "    original_question = sample[\"question_ja\"]\n",
        "\n",
        "    # 2. „É¢„Éá„É´„Å´ÂÖ•Âäõ„Åô„Çã„Åü„ÇÅ„ÅÆ„ÄåÂØæË©±ÂΩ¢Âºè„ÅÆ„Éó„É≠„É≥„Éó„Éà„Äç„Çí‰ΩúÊàê\n",
        "    #    ÂÖÉ„ÅÆ build_prompt „ÅÆÂÜÖÂÆπ„Çí user „É≠„Éº„É´„Å´ÈõÜÁ¥Ñ„Åó„Åæ„Åô\n",
        "    user_prompt = (\n",
        "        \"#ÊåáÁ§∫\\n\"\n",
        "        \"Ê¨°„ÅÆÊñáÁ´†„Çí‰ª•‰∏ã„ÅÆJSONÂΩ¢Âºè„Å´ÊßãÈÄ†Âåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\n\"\n",
        "        f\"{SCHEMA_STR}\\n\\n\"\n",
        "        \"#ÊäΩÂá∫ÂØæË±°\\n\"\n",
        "        f\"{original_question}\"\n",
        "    )\n",
        "\n",
        "    chat = [\n",
        "        # system„É≠„Éº„É´„ÅØ„É¢„Éá„É´„ÅÆÂΩπÂâ≤„ÇíÂÆöÁæ©„Åô„Çã„ÅÆ„Å´ÂΩπÁ´ã„Å°„Åæ„ÅôÔºàÁúÅÁï•ÂèØËÉΩ„Å™Â†¥Âêà„ÇÇ„ÅÇ„Çä„Åæ„ÅôÔºâ\n",
        "        {\"role\": \"system\", \"content\": \"\"},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    # 3. „ÉÅ„É£„ÉÉ„Éà„ÉÜ„É≥„Éó„É¨„Éº„Éà„ÇíÈÅ©Áî®„Åó„Å¶„Éà„Éº„ÇØ„Éä„Ç§„Ç∫\n",
        "    #    add_generation_prompt=True „Åß„ÄÅ„É¢„Éá„É´„ÅåÂøúÁ≠î„ÇíÂßã„ÇÅ„Çã„Åü„ÇÅ„ÅÆ„Éà„É™„Ç¨„ÉºÔºà‰æã: <|assistant|>Ôºâ„ÇíËøΩÂä†\n",
        "    tokenized_input = tokenizer.apply_chat_template(\n",
        "        chat,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # 4. Êé®Ë´ñ„ÇíÂÆüË°å\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            tokenized_input,\n",
        "            **GEN_KWARGS, # max_new_tokens„Å™„Å©„ÅÆË®≠ÂÆö„ÅØGEN_KWARGS„Å´„Åæ„Å®„ÇÅ„Å¶„ÅÇ„Çã„Å®‰ªÆÂÆö\n",
        "        )[0]\n",
        "\n",
        "    # 5. ÁîüÊàê„Åï„Çå„ÅüÈÉ®ÂàÜ„Å†„Åë„Çí„Éá„Ç≥„Éº„Éâ\n",
        "    #    ÂÖ•Âäõ„Éà„Éº„ÇØ„É≥Ôºà„Éó„É≠„É≥„Éó„ÉàÂÖ®‰ΩìÔºâ„ÅÆÈï∑„Åï„ÇíÂèñÂæó\n",
        "    input_token_len = len(tokenized_input[0])\n",
        "    # ÁîüÊàê„Åï„Çå„ÅüÈÉ®ÂàÜ„ÅÆ„Éà„Éº„ÇØ„É≥„Å†„Åë„Çí„Çπ„É©„Ç§„Çπ„ÅßÂèñ„ÇäÂá∫„Åô\n",
        "    generated_tokens = output[input_token_len:]\n",
        "    # „Éà„Éº„ÇØ„É≥„Çí„ÉÜ„Ç≠„Çπ„Éà„Å´„Éá„Ç≥„Éº„Éâ\n",
        "    output_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    # 6. ÁµêÊûú„Çí„É™„Çπ„Éà„Å´‰øùÂ≠ò\n",
        "    results.append({\n",
        "        \"input\": original_question,\n",
        "        \"model_output\": output_text.strip()\n",
        "    })\n",
        "\n",
        "    print(f\"--- „Çµ„É≥„Éó„É´ {i} ÂÆå‰∫Ü ---\")"
      ],
      "metadata": {
        "id": "qRBtcyTp6ri0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó3Ôºö„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠òÔºà„Åì„Åì„ÅØÂ§âÊõ¥„Å™„ÅóÔºâ ‚ñº‚ñº‚ñº\n",
        "# ====================================================\n",
        "# --- „Éï„Ç°„Ç§„É´Âêç„Çí„É¢„Éá„É´Âêç„Åã„ÇâËá™ÂãïÁîüÊàê ---\n",
        "modelname_2 = inference_model_2.split(\"/\")[-1]\n",
        "output_filename_2 = f\"eval_result_{modelname_2}.json\"\n",
        "\n",
        "# --- JSON„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò ---\n",
        "with open(output_filename_2, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Êé®Ë´ñÁµêÊûú„Çí {output_filename_2} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü„ÄÇ\")"
      ],
      "metadata": {
        "id": "Xu7yjtFS8qFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Êé®Ë´ñÁµêÊûú„Çí DataFrame „Å´Â§âÊèõ ---\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# --- Ë°®Á§∫Ë®≠ÂÆö ---\n",
        "pd.set_option('display.max_colwidth', None)   # Èï∑Êñá„ÇíÁúÅÁï•„Åõ„ÅöË°®Á§∫\n",
        "pd.set_option('display.max_rows', 100)        # Ë°®Á§∫Ë°åÊï∞„ÇíË™øÊï¥ÔºàÂøÖË¶Å„Å™„ÇâÂ¢ó„ÇÑ„ÅôÔºâ\n",
        "pd.set_option('display.width', None)          # Ê®™ÂπÖ„ÇíËá™ÂãïË™øÊï¥\n",
        "\n",
        "# --- Colab‰∏ä„Åß„Çπ„ÇØ„É≠„Éº„É´‰ªò„ÅçHTMLË°®Á§∫ ---\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# È´ò„Åï„ÉªÂπÖ„ÇíÊåáÂÆö„Åó„Å¶„Çπ„ÇØ„É≠„Éº„É´ÂèØËÉΩ„Å´\n",
        "scrollable_html = df_results.to_html(escape=False)\n",
        "display(HTML(f'<div style=\"max-height:600px; overflow-y:auto; border:1px solid #ccc;\">{scrollable_html}</div>'))"
      ],
      "metadata": {
        "id": "khhYRWig8mSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#02_Finetune"
      ],
      "metadata": {
        "id": "d5Mx9RXp0MVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‰ª•‰∏ã„ÅÆnotebook„ÇíÂèÇËÄÉ„Å´‰∫ãÂæåÂ≠¶Áøí„ÇíË°å„ÅÑ„Åæ„Åô  \n",
        "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb"
      ],
      "metadata": {
        "id": "GX_ilD-f0oFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###unsloth„ÅÆ„É©„Ç§„Éñ„É©„É™„Éº„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´"
      ],
      "metadata": {
        "id": "wMktybwLR093"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ],
      "metadata": {
        "id": "lyCl3T3O0QeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, math\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# --- „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊåáÂÆö ---\n",
        "DATASET_REPO = \"morizon/TCGA_Reports_ja_structured-filtered\"\n",
        "\n",
        "# --- „Éá„Éº„Çø„É≠„Éº„Éâ ---\n",
        "ds_all = load_dataset(DATASET_REPO)\n",
        "raw_ds = ds_all[\"train\"]\n",
        "\n",
        "total_len = len(raw_ds)\n",
        "train_size = math.floor(total_len * 0.95)\n",
        "raw_ds_train = raw_ds.select(range(0, train_size))\n",
        "raw_ds_eval = raw_ds.select(range(train_size, total_len))"
      ],
      "metadata": {
        "id": "etIjfkcAEc5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ÂÖ•Âäõ„Åô„Çãtoken„ÅÆ‰∏äÈôêË®≠ÂÆö„Åä„Çà„Å≥ÈáèÂ≠êÂåñ„ÅÆË®≠ÂÆö"
      ],
      "metadata": {
        "id": "2w7DfWbHR7ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
      ],
      "metadata": {
        "id": "IwZBmpva0dvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###„É¢„Éá„É´„ÅÆÊåáÂÆö„Åä„Çà„Å≥„É≠„Éº„Éâ"
      ],
      "metadata": {
        "id": "DIPV6YDmSAvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"llm-jp/llm-jp-3.1-1.8b\"\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = MODEL_ID,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "id": "7tlp6uk81HX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.config.name_or_path)\n",
        "print(model.config._name_or_path)  # HF„ÅÆ„Ç≠„É£„ÉÉ„Ç∑„É•Âêç„ÇíÊòéÁ§∫\n",
        "print(model.config.model_type)\n",
        "print(model.config.architectures)\n",
        "print(model.config.torch_dtype)\n",
        "print(model.generation_config)"
      ],
      "metadata": {
        "id": "H355sVUznshD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â≠¶ÁøíÊôÇ„ÅÆlora„ÅÆË®≠ÂÆö"
      ],
      "metadata": {
        "id": "6dwooSTQSJnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "id": "79U2lVi01y_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import login\n",
        "# from google.colab import userdata\n",
        "\n",
        "# HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "# login(token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "q1bCJtyVaKDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â≠¶Áøí„Éá„Éº„Çø„ÅÆÊï¥ÂΩ¢"
      ],
      "metadata": {
        "id": "9Ni7nyCDSPxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === ‚ë¢ Âá∫Âäõ„Çπ„Ç≠„Éº„ÉûÔºàÂõ∫ÂÆöÂΩ¢ÂºèÔºâ ===\n",
        "SCHEMA_STR = (\n",
        "    '{{ \"ËáìÂô®\": \"\", \"Êé°ÂèñÊñπÊ≥ï\": \"\", \"Ë®∫Êñ≠\": \"\", \"ÂàÜÂåñÂ∫¶\": \"\", '\n",
        "    '\"ÁóÖÊúü\": \"\", \"ËÖ´ÁòçÂæÑ\": \"\", \"Êµ∏ÊΩ§ÁØÑÂõ≤\": \"\", \"Êñ≠Á´Ø\": \"\", \"„Åù„ÅÆ‰ªñÊâÄË¶ã\": \"\" }}'\n",
        ")\n",
        "\n",
        "INSTR_TEMPLATE = (\n",
        "    \"#ÊåáÁ§∫\\n\"\n",
        "    \"Ê¨°„ÅÆÊñáÁ´†„Çí‰ª•‰∏ã„ÅÆJSONÂΩ¢Âºè„Å´ÊßãÈÄ†Âåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\n\"\n",
        "    f\"{SCHEMA_STR}\\n\\n\"\n",
        "    \"#ÊäΩÂá∫ÂØæË±°\\n\"\n",
        "    \"{}\"\n",
        ")\n",
        "\n",
        "# === ‚ë£ answer_ja „ÅÆJSONÊï¥ÂΩ¢Ë£úÂä© ===\n",
        "def _to_json_str(s):\n",
        "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
        "        return \"{}\"\n",
        "    if isinstance(s, dict):\n",
        "        return json.dumps(s, ensure_ascii=False)\n",
        "    if isinstance(s, str):\n",
        "        try:\n",
        "            repaired = s.replace('\"\"', '\"')\n",
        "            parsed = json.loads(repaired)\n",
        "            return json.dumps(parsed, ensure_ascii=False)\n",
        "        except Exception:\n",
        "            return s\n",
        "    return str(s)\n",
        "\n",
        "# === ‚ë§ Hugging Face Dataset ‚Üí SFTÂΩ¢ÂºèÂ§âÊèõ ===\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    q_ja_list = examples.get(\"question_ja\", [])\n",
        "    a_ja_list = examples.get(\"answer_ja\", [])\n",
        "\n",
        "    texts = []\n",
        "    for q_ja, a_ja in zip(q_ja_list, a_ja_list):\n",
        "        q_ja = \"\" if q_ja is None or (isinstance(q_ja, float) and math.isnan(q_ja)) else str(q_ja).strip()\n",
        "        instr = INSTR_TEMPLATE.format(q_ja)\n",
        "        out_json_str = _to_json_str(a_ja).strip()\n",
        "        text = instr + \"\\n\" + out_json_str + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "\n",
        "    return {\"text\": texts}\n",
        "\n",
        "dataset = raw_ds_train.map(formatting_prompts_func, batched=True, remove_columns=raw_ds_train.column_names)\n",
        "\n",
        "print(\"‚úÖ dataset ready:\", dataset)\n",
        "print(dataset[0][\"text\"])"
      ],
      "metadata": {
        "id": "Se0Uks-SaFVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â≠¶ÁøíÊôÇ„ÅÆ„Éë„É©„É°„Éº„ÇøË®≠ÂÆö"
      ],
      "metadata": {
        "id": "tipWmrcLSXJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig, SFTTrainer\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 2,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 30,\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 5,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.001,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use TrackIO/WandB etc\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "wNLabWdp6Zo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###„É°„É¢„É™‰ΩøÁî®Èáè"
      ],
      "metadata": {
        "id": "iDjB8Ec6Se8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "id": "WQQlCVdT6cr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â≠¶Áøí„ÅÆÂÆüË°å"
      ],
      "metadata": {
        "id": "9pIgUpamSjtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "JqEorCW2E0XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ],
      "metadata": {
        "id": "s6_V0JPG6kta",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"llm-jp-3.1-1.8b_tcga_sft_n95_step30_lora\")  # Local saving\n",
        "tokenizer.save_pretrained(\"llm-jp-3.1-1.8b_tcga_sft_n95_step30_lora\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ],
      "metadata": {
        "id": "PpG3WgQkjj5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCHEMA_STR = (\n",
        "    '{ \"ËáìÂô®\": \"\", \"Êé°ÂèñÊñπÊ≥ï\": \"\", \"Ë®∫Êñ≠\": \"\", \"ÂàÜÂåñÂ∫¶\": \"\", '\n",
        "    '\"ÁóÖÊúü\": \"\", \"ËÖ´ÁòçÂæÑ\": \"\", \"Êµ∏ÊΩ§ÁØÑÂõ≤\": \"\", \"Êñ≠Á´Ø\": \"\", \"„Åù„ÅÆ‰ªñÊâÄË¶ã\": \"\" }'\n",
        ")\n",
        "\n",
        "def build_prompt(text):\n",
        "    return (\n",
        "        \"#ÊåáÁ§∫\\n\"\n",
        "        \"Ê¨°„ÅÆÊñáÁ´†„Çí‰ª•‰∏ã„ÅÆJSONÂΩ¢Âºè„Å´ÊßãÈÄ†Âåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\n\"\n",
        "        f\"{SCHEMA_STR}\\n\\n\"\n",
        "        \"#ÊäΩÂá∫ÂØæË±°\\n\"\n",
        "        f\"{text}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "S893EfAYWBBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â≠¶ÁøíÂæå„ÅÆÂá∫ÂäõÁ¢∫Ë™ç"
      ],
      "metadata": {
        "id": "J4pI7dSxSwGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GEN_KWARGS = dict(\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    top_p=0.95,\n",
        "    temperature=0.7,\n",
        "    repetition_penalty=1.05,\n",
        ")"
      ],
      "metadata": {
        "id": "JjKHEUDEEpl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó1ÔºöÂàùÊúüË®≠ÂÆöÔºà„É´„Éº„Éó„ÅÆÂâç„Å´‰∏ÄÂ∫¶„Å†„ÅëÂÆüË°åÔºâ ‚ñº‚ñº‚ñº\n",
        "# ----------------------------------------------------\n",
        "print(\"„É¢„Éá„É´„ÇíÊé®Ë´ñÁî®„Å´ÊúÄÈÅ©Âåñ„Åó„Åæ„Åô...Ôºà„Åì„ÅÆÂá¶ÁêÜ„ÅØ‰∏ÄÂ∫¶„Å†„ÅëÂÆüË°å„Åï„Çå„Åæ„ÅôÔºâ\")\n",
        "\n",
        "# Unsloth„Å´„Çà„ÇãÊé®Ë´ñÊúÄÈÅ©Âåñ\n",
        "FastLanguageModel.for_inference(model)\n",
        "# Ë©ï‰æ°„É¢„Éº„Éâ„Å´Ë®≠ÂÆö\n",
        "model.eval()\n",
        "\n",
        "# PAD„Éà„Éº„ÇØ„É≥„ÅÆË®≠ÂÆö\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "L_F6RGEUfSVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó2ÔºöÊé®Ë´ñ„É´„Éº„Éó„Å®ÁµêÊûú„ÅÆ‰øùÂ≠ò ‚ñº‚ñº‚ñº\n",
        "# ----------------------------------------------------\n",
        "results = [] # Êé®Ë´ñÁµêÊûú„ÇíÊ†ºÁ¥ç„Åô„Çã„Åü„ÇÅ„ÅÆÁ©∫„ÅÆ„É™„Çπ„Éà„ÇíÂàùÊúüÂåñ\n",
        "\n",
        "# raw_ds_eval „ÅÆ„Åô„Åπ„Å¶„ÅÆ„Çµ„É≥„Éó„É´„Å´ÂØæ„Åó„Å¶„É´„Éº„Éó„ÇíÂÆüË°å\n",
        "for idx, sample in enumerate(raw_ds_eval):\n",
        "    print(f\"==================== „Çµ„É≥„Éó„É´ {idx} ====================\")\n",
        "\n",
        "    # 1. „Éá„Éº„Çø„Çª„ÉÉ„Éà„Åã„ÇâÂÖÉ„ÅÆË≥™ÂïèÊñá„ÇíÂèñÂæó„Åó„ÄÅ„Éó„É≠„É≥„Éó„Éà„ÇíÊßãÁØâ\n",
        "    # ‚òÖ JSON‰øùÂ≠òÁî®„Å´ÂÖÉ„ÅÆË≥™ÂïèÊñá„ÇÇÂ§âÊï∞„Å´‰øùÊåÅ„Åó„Å¶„Åä„Åè\n",
        "    original_question = sample[\"question_ja\"]\n",
        "    text = build_prompt(original_question)\n",
        "\n",
        "    # print(\"\\n--- ÂÖ•Âäõ„Éó„É≠„É≥„Éó„Éà ---\")\n",
        "    # print(text)\n",
        "\n",
        "    # 2. „Éó„É≠„É≥„Éó„Éà„Çí„Éà„Éº„ÇØ„Éä„Ç§„Ç∫\n",
        "    tokenized_input = tokenizer.encode(\n",
        "        text, add_special_tokens=False, return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # 3. Êé®Ë´ñ„ÅÆÂÆüË°å\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            tokenized_input,\n",
        "            **GEN_KWARGS,\n",
        "        )[0]\n",
        "\n",
        "    # 4. ÁîüÊàê„Åï„Çå„ÅüÈÉ®ÂàÜ„Å†„Åë„Çí„Éá„Ç≥„Éº„Éâ\n",
        "    input_token_len = len(tokenized_input[0])\n",
        "    generated_tokens = output[input_token_len:]\n",
        "    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    # 5. ÁîüÊàêÁµêÊûú„Çí„Ç≥„É≥„ÇΩ„Éº„É´„Å´Ë°®Á§∫\n",
        "    print(\"\\n--- „É¢„Éá„É´„ÅÆÁîüÊàêÁµêÊûú (ÁîüÊàêÈÉ®ÂàÜ„ÅÆ„Åø) ---\")\n",
        "    print(generated_text.strip()) # .strip()„ÅßÂâçÂæå„ÅÆÁ©∫ÁôΩ„ÇíÈô§Âéª\n",
        "    print(f\"==================== „Çµ„É≥„Éó„É´ {idx} ÁµÇ‰∫Ü ====================\\n\")\n",
        "\n",
        "    # 6. ÁµêÊûú„Çí„É™„Çπ„Éà„Å´ËøΩÂä†\n",
        "    results.append({\n",
        "        \"input\": original_question,           # ÂÖÉ„ÅÆË≥™ÂïèÊñá\n",
        "        \"model_output\": generated_text.strip() # „É¢„Éá„É´„ÅÆÂá∫Âäõ\n",
        "    })\n",
        "\n",
        "    # #„Äê‰ªªÊÑè„Äë„ÉÜ„Çπ„ÉàÁî®„Å´ÊúÄÂàù„ÅÆÊï∞‰ª∂„Åß„É´„Éº„Éó„ÇíÊ≠¢„ÇÅ„Åü„ÅÑÂ†¥Âêà\n",
        "    # if idx >= 1:\n",
        "    #     break"
      ],
      "metadata": {
        "id": "C7SHYLcxgguE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó3ÔºöJSON„Éï„Ç°„Ç§„É´„Å∏„ÅÆÊõ∏„ÅçËæº„Åø ‚ñº‚ñº‚ñº\n",
        "# ----------------------------------------------------\n",
        "output_filename_sft = f\"eval_result_sft.json\"\n",
        "\n",
        "# --- JSON„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò ---\n",
        "with open(output_filename_sft , \"w\", encoding=\"utf-8\") as f:\n",
        "    # ensure_ascii=False „ÅßÊó•Êú¨Ë™û„ÅåÊñáÂ≠óÂåñ„Åë„Åó„Å™„ÅÑ„Çà„ÅÜ„Å´„Åô„Çã\n",
        "    # indent=2 „Åß‰∫∫Èñì„ÅåË™≠„Åø„ÇÑ„Åô„ÅÑ„Çà„ÅÜ„Å´Êï¥ÂΩ¢„Åô„Çã\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"‚úÖ ÂÖ®„Å¶„ÅÆÊé®Ë´ñ„ÅåÂÆå‰∫Ü„Åó„ÄÅÁµêÊûú„Çí {output_filename_sft } „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü„ÄÇ\")"
      ],
      "metadata": {
        "id": "am7iDptMgkC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Êé®Ë´ñÁµêÊûú„Çí DataFrame „Å´Â§âÊèõ ---\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# --- Ë°®Á§∫Ë®≠ÂÆö ---\n",
        "pd.set_option('display.max_colwidth', None)   # Èï∑Êñá„ÇíÁúÅÁï•„Åõ„ÅöË°®Á§∫\n",
        "pd.set_option('display.max_rows', 100)        # Ë°®Á§∫Ë°åÊï∞„ÇíË™øÊï¥ÔºàÂøÖË¶Å„Å™„ÇâÂ¢ó„ÇÑ„ÅôÔºâ\n",
        "pd.set_option('display.width', None)          # Ê®™ÂπÖ„ÇíËá™ÂãïË™øÊï¥\n",
        "\n",
        "# --- Colab‰∏ä„Åß„Çπ„ÇØ„É≠„Éº„É´‰ªò„ÅçHTMLË°®Á§∫ ---\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# È´ò„Åï„ÉªÂπÖ„ÇíÊåáÂÆö„Åó„Å¶„Çπ„ÇØ„É≠„Éº„É´ÂèØËÉΩ„Å´\n",
        "scrollable_html = df_results.to_html(escape=False)\n",
        "display(HTML(f'<div style=\"max-height:600px; overflow-y:auto; border:1px solid #ccc;\">{scrollable_html}</div>'))"
      ],
      "metadata": {
        "id": "kMBt4AfphBS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â≠¶ÁøíÂæå„ÅÆ„É¢„Éá„É´„ÅÆ„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ_‰ΩøÁî®„Åó„Åæ„Åõ„Çì(„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂæå„Å´„É¢„Éá„É´„ÇíÊé®Ë´ñ„Åô„Çã„Å®Âá∫Âäõ„Åå„Åä„Åã„Åó„ÅÑ„Åü„ÇÅ)"
      ],
      "metadata": {
        "id": "0UNg6m-ryuOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Merge to 16bit\n",
        "# model.save_pretrained_merged(\"llm-jp-3.1-1.8b_tcga_sft_n100_step30\", tokenizer, save_method = \"merged_16bit\",)\n",
        "# model.push_to_hub_merged(\"morizon/llm-jp-3.1-1.8b_tcga_sft_n100_step30\", tokenizer, save_method = \"merged_16bit\",token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "XeZVUOx3xWku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # LoRA„Ç¢„ÉÄ„Éó„Çø„Å†„Åë‰øùÂ≠ò\n",
        "# model.save_pretrained_merged(\"llm-jp-3.1-1.8b_tcga_sft_n100_step30_lora\", tokenizer, save_method = \"lora\",)\n",
        "# model.push_to_hub_merged(\n",
        "#     \"morizon/llm-jp-3.1-1.8b_tcga_sft_n100_step30_lora\",\n",
        "#     tokenizer=tokenizer,\n",
        "#     save_method=\"lora\",\n",
        "#     token=HF_TOKEN\n",
        "# )"
      ],
      "metadata": {
        "id": "-4lNzp-_x02D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#03_eval"
      ],
      "metadata": {
        "id": "mBjDUUoz3Naz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##03-1_Â≠¶ÁøíÂâç„ÅÆ„É¢„Éá„É´„ÅÆË©ï‰æ°_llm-jp/llm-jp-3.1-1.8b"
      ],
      "metadata": {
        "id": "9Wucwg8Ak5Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_model_1=\"llm-jp/llm-jp-3.1-1.8b\""
      ],
      "metadata": {
        "id": "FUSEbcx4_EiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "TTS_vsp5PXRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "# --- 1. Ê∫ñÂÇô ---\n",
        "\n",
        "# API„Ç≠„Éº„ÅÆË®≠ÂÆö (ÂøÖ„ÅöYOUR_API_KEY„ÅÆÈÉ®ÂàÜ„ÇíÂÆüÈöõ„ÅÆ„Ç≠„Éº„Å´ÁΩÆ„ÅçÊèõ„Åà„Å¶„Åè„Å†„Åï„ÅÑ)\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "judge_model = genai.GenerativeModel('gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "fnZxPCWZPUPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Gemini API Êé•Á∂ö„ÉÜ„Çπ„ÉàÈñãÂßã ---\")\n",
        "\n",
        "# Á∞°Âçò„ÅßÁÑ°ÂÆ≥„Å™„Éó„É≠„É≥„Éó„Éà„ÇíÁî®ÊÑè\n",
        "test_prompt = \"„Åì„Çì„Å´„Å°„ÅØÔºÅLLM„Å´„Å§„ÅÑ„Å¶Á∞°ÊΩî„Å´100ÊñáÂ≠óÁ®ãÂ∫¶„ÅßÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
        "\n",
        "try:\n",
        "    print(\"API„Å´„É™„ÇØ„Ç®„Çπ„Éà„ÇíÈÄÅ‰ø°‰∏≠... („Çø„Ç§„É†„Ç¢„Ç¶„Éà: 60Áßí)\")\n",
        "\n",
        "    # API„ÇíÂëº„Å≥Âá∫„ÅôÈöõ„Å´„ÄÅrequest_options„Åß„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÇíÊåáÂÆö\n",
        "    # ‚òÖ‚òÖ‚òÖ „Åì„Åì„ÅåÈáçË¶Å ‚òÖ‚òÖ‚òÖ\n",
        "    response = judge_model.generate_content(\n",
        "        test_prompt,\n",
        "        request_options={\"timeout\": 60}  # 60Áßí„Åß„Çø„Ç§„É†„Ç¢„Ç¶„Éà\n",
        "    )\n",
        "\n",
        "    print(\"API„Åã„ÇâÂøúÁ≠î„Åå„ÅÇ„Çä„Åæ„Åó„ÅüÔºÅ\")\n",
        "    print(\"-\" * 20)\n",
        "    print(\"ÂøúÁ≠î„ÉÜ„Ç≠„Çπ„Éà:\")\n",
        "    print(response.text)\n",
        "    print(\"-\" * 20)\n",
        "    print(\"‚úÖ „ÉÜ„Çπ„ÉàÊàêÂäü: API„ÅØÊ≠£Â∏∏„Å´Âãï‰Ωú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\")\n",
        "\n",
        "# google.api_core.exceptions.DeadlineExceeded „ÅÆ„Çà„ÅÜ„Å™„Çø„Ç§„É†„Ç¢„Ç¶„ÉàÂõ∫Êúâ„ÅÆ„Ç®„É©„Éº„Çí„Ç≠„É£„ÉÉ„ÉÅ„Åô„Çã„Åì„Å®„ÇÇÂèØËÉΩ\n",
        "except Exception as e:\n",
        "    print(\"\\n‚ùå „ÉÜ„Çπ„ÉàÂ§±Êïó: APIÂëº„Å≥Âá∫„Åó‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "    print(\"--- „Ç®„É©„ÉºË©≥Á¥∞ ---\")\n",
        "    # „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„ÅüÂ†¥Âêà„ÄÅ„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Å´ \"Deadline Exceeded\" „ÇÑ \"Timeout\" „Å®„ÅÑ„Å£„ÅüÊñáË®Ä„ÅåÂê´„Åæ„Çå„Åæ„Åô\n",
        "    print(e)\n",
        "    print(\"--------------------\")\n",
        "    # „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„Åü„Åã„Å©„ÅÜ„Åã„ÇíÂà§ÂÆö„Åô„Çã\n",
        "    if \"deadline\" in str(e).lower() or \"timeout\" in str(e).lower():\n",
        "        print(\"üí° „Éí„É≥„Éà: 60Áßí‰ª•ÂÜÖ„Å´ÂøúÁ≠î„Åå„Å™„Åã„Å£„Åü„Åü„ÇÅ„ÄÅ„Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„ÅüÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Gemini API Êé•Á∂ö„ÉÜ„Çπ„ÉàÁµÇ‰∫Ü ---\")"
      ],
      "metadata": {
        "id": "VPt6MtMYuUnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# --- „É¢„Éá„É´Âêç„Éª„Éï„Ç°„Ç§„É´ÂêçË®≠ÂÆö ---\n",
        "modelname = inference_model_1.split(\"/\")[-1]\n",
        "date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "input_filename = f\"eval_result_{modelname}.json\"\n",
        "output_filename = f\"eval_scored_results_{modelname}_{date_str}.json\"\n",
        "csv_filename = f\"eval_scored_results_{modelname}_{date_str}.csv\"\n",
        "\n",
        "# --- Êé®Ë´ñÁµêÊûú„Çí„É≠„Éº„Éâ ---\n",
        "with open(input_filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    eval_results = json.load(f)\n",
        "\n",
        "evaluated = []\n",
        "\n",
        "# --- Gemini„ÅßÂêÑÂá∫Âäõ„ÇíË©ï‰æ° ---\n",
        "for item in eval_results:\n",
        "    prompt = f\"\"\"\n",
        "„ÅÇ„Å™„Åü„ÅØ„ÄÅÂåªÁôÇ„ÉÜ„Ç≠„Çπ„ÉàÊßãÈÄ†Âåñ„É¢„Éá„É´„ÅÆÂá∫Âäõ„ÇíË©ï‰æ°„Åô„ÇãÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ\n",
        "\n",
        "# ÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà\n",
        "{item[\"input\"]}\n",
        "\n",
        "# „É¢„Éá„É´„ÅÆÂá∫Âäõ\n",
        "{item[\"model_output\"]}\n",
        "\n",
        "Ê¨°„ÅÆ3„Å§„ÅÆË¶≥ÁÇπ„Åã„ÇâË©ï‰æ°„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "1. **ÂΩ¢Âºè„ÅÆÊ≠£Á¢∫ÊÄß**ÔºöÂá∫Âäõ„ÅåÊßãÈÄ†ÂåñÂΩ¢Âºè(JSON)„Å®„Åó„Å¶Â¶•ÂΩì„Åã„ÄÇ\n",
        "2. **ÊÉÖÂ†±„ÅÆÁ∂≤ÁæÖÊÄß**ÔºöÂøÖË¶Å„Å™ÊÉÖÂ†±ÔºàËáìÂô®„ÉªË®∫Êñ≠„ÉªÁóÖÊúü„Å™„Å©Ôºâ„ÇíÂçÅÂàÜ„Å´Âê´„Çì„Åß„ÅÑ„Çã„Åã„ÄÇ\n",
        "3. **ÂÜÖÂÆπ„ÅÆÊ≠£Á¢∫ÊÄß**ÔºöÊäΩÂá∫ÂÜÖÂÆπ„ÅåÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„ÅÆ‰∫ãÂÆü„Å®‰∏ÄËá¥„Åó„Å¶„ÅÑ„Çã„Åã„ÄÇ\n",
        "\n",
        "---\n",
        "\n",
        "Ë©ï‰æ°ÁµêÊûú„ÅØ‰ª•‰∏ã„ÅÆ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Åß„ÄÅÊó•Êú¨Ë™û„ÅßÁ∞°ÊΩî„Å´Âá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "\n",
        "score: <0.0„Äú1.0„ÅÆÊï∞ÂÄ§>\n",
        "ÂΩ¢Âºè„ÅÆÊ≠£Á¢∫ÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "ÊÉÖÂ†±„ÅÆÁ∂≤ÁæÖÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "ÂÜÖÂÆπ„ÅÆÊ≠£Á¢∫ÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "Á∑èÂêà„Ç≥„É°„É≥„Éà: <ÂÖ®‰ΩìÁöÑ„Å™Ë©ï‰æ°„Çí‰∏ÄÊñá„Åß„Åæ„Å®„ÇÅ„Çã>\n",
        "\"\"\"\n",
        "\n",
        "    judge_response = judge_model.generate_content(prompt)\n",
        "    raw_text = judge_response.text.strip()\n",
        "\n",
        "    # --- „Ç≥„Éº„Éâ„Éñ„É≠„ÉÉ„ÇØ„ÇíÈô§ÂéªÔºà```json ... ``` „ÇÑ ``` ... ```Ôºâ---\n",
        "    cleaned_text = re.sub(r\"^```(?:json)?|```$\", \"\", raw_text, flags=re.MULTILINE).strip()\n",
        "\n",
        "    # --- JSON„Éë„Éº„ÇπË©¶Ë°å ---\n",
        "    try:\n",
        "        evaluation = json.loads(cleaned_text)\n",
        "    except json.JSONDecodeError:\n",
        "        # JSON„Å®„Åó„Å¶„Éë„Éº„Çπ„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÄÅ„Çπ„Ç≥„Ç¢„Å†„ÅëÊ≠£Ë¶èË°®Áèæ„ÅßÊäΩÂá∫\n",
        "        score_match = re.search(r'\"?score\"?\\s*[:Ôºö]\\s*([0-9.]+)', cleaned_text)\n",
        "        score = float(score_match.group(1)) if score_match else None\n",
        "        evaluation = {\"score\": score, \"reason\": cleaned_text}\n",
        "\n",
        "    evaluated.append({\n",
        "        \"input\": item[\"input\"][:100] + \"...\",\n",
        "        \"output\": item[\"model_output\"][:150] + \"...\",\n",
        "        \"score\": evaluation.get(\"score\"),\n",
        "        \"reason\": evaluation.get(\"reason\"),\n",
        "    })\n",
        "\n",
        "    # # ÊúÄÂàù„ÅÆ1‰ª∂„ÅÆÂá¶ÁêÜ„ÅåÁµÇ„Çè„Å£„Åü„ÅÆ„Åß„ÄÅ„É´„Éº„Éó„ÇíÂº∑Âà∂ÁöÑ„Å´ÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ\n",
        "    # print(\"„ÉÜ„Çπ„Éà„ÅÆ„Åü„ÇÅ„ÄÅÊúÄÂàù„ÅÆ1‰ª∂„ÅßÂá¶ÁêÜ„ÇíÂÅúÊ≠¢„Åó„Åæ„Åô„ÄÇ\")\n",
        "    # break\n",
        "    # -----------------------------------------------\n",
        "\n",
        "# --- DataFrame„Å´„Åó„Å¶‰øùÂ≠ò ---\n",
        "df = pd.DataFrame(evaluated)\n",
        "df.to_json(output_filename, orient=\"records\", force_ascii=False, indent=2)\n",
        "df.to_csv(csv_filename, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"‚úÖ Êé°ÁÇπÁµêÊûú„Çí {csv_filename} „Å® {output_filename} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "\n",
        "# --- Colab„Åß„Çπ„ÇØ„É≠„Éº„É´„Åó„ÇÑ„Åô„ÅèÂÖ®ÊñáË°®Á§∫ ---\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', None)\n",
        "display(df.head(10))"
      ],
      "metadata": {
        "id": "nUOxBbsnOuYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##03-2_„É¢„Éá„É´„ÅÆË©ï‰æ°_llm-jp/llm-jp-3.1-1.8b-instruct4"
      ],
      "metadata": {
        "id": "U_SKisII782P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_model_2=\"llm-jp/llm-jp-3.1-1.8b-instruct4\""
      ],
      "metadata": {
        "id": "nKUvqo-5-_Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "eACIf_8J8BoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "# --- 1. Ê∫ñÂÇô ---\n",
        "\n",
        "# API„Ç≠„Éº„ÅÆË®≠ÂÆö (ÂøÖ„ÅöYOUR_API_KEY„ÅÆÈÉ®ÂàÜ„ÇíÂÆüÈöõ„ÅÆ„Ç≠„Éº„Å´ÁΩÆ„ÅçÊèõ„Åà„Å¶„Åè„Å†„Åï„ÅÑ)\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "judge_model = genai.GenerativeModel('gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "rxXkCypx8BoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Gemini API Êé•Á∂ö„ÉÜ„Çπ„ÉàÈñãÂßã ---\")\n",
        "\n",
        "# Á∞°Âçò„ÅßÁÑ°ÂÆ≥„Å™„Éó„É≠„É≥„Éó„Éà„ÇíÁî®ÊÑè\n",
        "test_prompt = \"„Åì„Çì„Å´„Å°„ÅØÔºÅLLM„Å´„Å§„ÅÑ„Å¶Á∞°ÊΩî„Å´100ÊñáÂ≠óÁ®ãÂ∫¶„ÅßÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
        "\n",
        "try:\n",
        "    print(\"API„Å´„É™„ÇØ„Ç®„Çπ„Éà„ÇíÈÄÅ‰ø°‰∏≠... („Çø„Ç§„É†„Ç¢„Ç¶„Éà: 60Áßí)\")\n",
        "\n",
        "    # API„ÇíÂëº„Å≥Âá∫„ÅôÈöõ„Å´„ÄÅrequest_options„Åß„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÇíÊåáÂÆö\n",
        "    # ‚òÖ‚òÖ‚òÖ „Åì„Åì„ÅåÈáçË¶Å ‚òÖ‚òÖ‚òÖ\n",
        "    response = judge_model.generate_content(\n",
        "        test_prompt,\n",
        "        request_options={\"timeout\": 60}  # 60Áßí„Åß„Çø„Ç§„É†„Ç¢„Ç¶„Éà\n",
        "    )\n",
        "\n",
        "    print(\"API„Åã„ÇâÂøúÁ≠î„Åå„ÅÇ„Çä„Åæ„Åó„ÅüÔºÅ\")\n",
        "    print(\"-\" * 20)\n",
        "    print(\"ÂøúÁ≠î„ÉÜ„Ç≠„Çπ„Éà:\")\n",
        "    print(response.text)\n",
        "    print(\"-\" * 20)\n",
        "    print(\"‚úÖ „ÉÜ„Çπ„ÉàÊàêÂäü: API„ÅØÊ≠£Â∏∏„Å´Âãï‰Ωú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\")\n",
        "\n",
        "# google.api_core.exceptions.DeadlineExceeded „ÅÆ„Çà„ÅÜ„Å™„Çø„Ç§„É†„Ç¢„Ç¶„ÉàÂõ∫Êúâ„ÅÆ„Ç®„É©„Éº„Çí„Ç≠„É£„ÉÉ„ÉÅ„Åô„Çã„Åì„Å®„ÇÇÂèØËÉΩ\n",
        "except Exception as e:\n",
        "    print(\"\\n‚ùå „ÉÜ„Çπ„ÉàÂ§±Êïó: APIÂëº„Å≥Âá∫„Åó‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "    print(\"--- „Ç®„É©„ÉºË©≥Á¥∞ ---\")\n",
        "    # „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„ÅüÂ†¥Âêà„ÄÅ„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Å´ \"Deadline Exceeded\" „ÇÑ \"Timeout\" „Å®„ÅÑ„Å£„ÅüÊñáË®Ä„ÅåÂê´„Åæ„Çå„Åæ„Åô\n",
        "    print(e)\n",
        "    print(\"--------------------\")\n",
        "    # „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„Åü„Åã„Å©„ÅÜ„Åã„ÇíÂà§ÂÆö„Åô„Çã\n",
        "    if \"deadline\" in str(e).lower() or \"timeout\" in str(e).lower():\n",
        "        print(\"üí° „Éí„É≥„Éà: 60Áßí‰ª•ÂÜÖ„Å´ÂøúÁ≠î„Åå„Å™„Åã„Å£„Åü„Åü„ÇÅ„ÄÅ„Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„ÅüÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Gemini API Êé•Á∂ö„ÉÜ„Çπ„ÉàÁµÇ‰∫Ü ---\")"
      ],
      "metadata": {
        "id": "vjJfG1cN8BoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# --- „É¢„Éá„É´Âêç„Éª„Éï„Ç°„Ç§„É´ÂêçË®≠ÂÆö ---\n",
        "modelname = inference_model_2.split(\"/\")[-1]\n",
        "date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "input_filename = f\"eval_result_{modelname}.json\"\n",
        "output_filename = f\"eval_scored_results_{modelname}_{date_str}.json\"\n",
        "csv_filename = f\"eval_scored_results_{modelname}_{date_str}.csv\"\n",
        "\n",
        "# --- Êé®Ë´ñÁµêÊûú„Çí„É≠„Éº„Éâ ---\n",
        "with open(input_filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    eval_results = json.load(f)\n",
        "\n",
        "evaluated = []\n",
        "\n",
        "# --- Gemini„ÅßÂêÑÂá∫Âäõ„ÇíË©ï‰æ° ---\n",
        "for item in eval_results:\n",
        "    prompt = f\"\"\"\n",
        "„ÅÇ„Å™„Åü„ÅØ„ÄÅÂåªÁôÇ„ÉÜ„Ç≠„Çπ„ÉàÊßãÈÄ†Âåñ„É¢„Éá„É´„ÅÆÂá∫Âäõ„ÇíË©ï‰æ°„Åô„ÇãÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ\n",
        "\n",
        "# ÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà\n",
        "{item[\"input\"]}\n",
        "\n",
        "# „É¢„Éá„É´„ÅÆÂá∫Âäõ\n",
        "{item[\"model_output\"]}\n",
        "\n",
        "Ê¨°„ÅÆ3„Å§„ÅÆË¶≥ÁÇπ„Åã„ÇâË©ï‰æ°„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "1. **ÂΩ¢Âºè„ÅÆÊ≠£Á¢∫ÊÄß**ÔºöÂá∫Âäõ„ÅåÊßãÈÄ†ÂåñÂΩ¢Âºè(JSON)„Å®„Åó„Å¶Â¶•ÂΩì„Åã„ÄÇ\n",
        "2. **ÊÉÖÂ†±„ÅÆÁ∂≤ÁæÖÊÄß**ÔºöÂøÖË¶Å„Å™ÊÉÖÂ†±ÔºàËáìÂô®„ÉªË®∫Êñ≠„ÉªÁóÖÊúü„Å™„Å©Ôºâ„ÇíÂçÅÂàÜ„Å´Âê´„Çì„Åß„ÅÑ„Çã„Åã„ÄÇ\n",
        "3. **ÂÜÖÂÆπ„ÅÆÊ≠£Á¢∫ÊÄß**ÔºöÊäΩÂá∫ÂÜÖÂÆπ„ÅåÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„ÅÆ‰∫ãÂÆü„Å®‰∏ÄËá¥„Åó„Å¶„ÅÑ„Çã„Åã„ÄÇ\n",
        "\n",
        "---\n",
        "\n",
        "Ë©ï‰æ°ÁµêÊûú„ÅØ‰ª•‰∏ã„ÅÆ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Åß„ÄÅÊó•Êú¨Ë™û„ÅßÁ∞°ÊΩî„Å´Âá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "\n",
        "score: <0.0„Äú1.0„ÅÆÊï∞ÂÄ§>\n",
        "ÂΩ¢Âºè„ÅÆÊ≠£Á¢∫ÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "ÊÉÖÂ†±„ÅÆÁ∂≤ÁæÖÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "ÂÜÖÂÆπ„ÅÆÊ≠£Á¢∫ÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "Á∑èÂêà„Ç≥„É°„É≥„Éà: <ÂÖ®‰ΩìÁöÑ„Å™Ë©ï‰æ°„Çí‰∏ÄÊñá„Åß„Åæ„Å®„ÇÅ„Çã>\n",
        "\"\"\"\n",
        "\n",
        "    judge_response = judge_model.generate_content(prompt)\n",
        "    raw_text = judge_response.text.strip()\n",
        "\n",
        "    # --- „Ç≥„Éº„Éâ„Éñ„É≠„ÉÉ„ÇØ„ÇíÈô§ÂéªÔºà```json ... ``` „ÇÑ ``` ... ```Ôºâ---\n",
        "    cleaned_text = re.sub(r\"^```(?:json)?|```$\", \"\", raw_text, flags=re.MULTILINE).strip()\n",
        "\n",
        "    # --- JSON„Éë„Éº„ÇπË©¶Ë°å ---\n",
        "    try:\n",
        "        evaluation = json.loads(cleaned_text)\n",
        "    except json.JSONDecodeError:\n",
        "        # JSON„Å®„Åó„Å¶„Éë„Éº„Çπ„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÄÅ„Çπ„Ç≥„Ç¢„Å†„ÅëÊ≠£Ë¶èË°®Áèæ„ÅßÊäΩÂá∫\n",
        "        score_match = re.search(r'\"?score\"?\\s*[:Ôºö]\\s*([0-9.]+)', cleaned_text)\n",
        "        score = float(score_match.group(1)) if score_match else None\n",
        "        evaluation = {\"score\": score, \"reason\": cleaned_text}\n",
        "\n",
        "    evaluated.append({\n",
        "        \"input\": item[\"input\"][:100] + \"...\",\n",
        "        \"output\": item[\"model_output\"][:150] + \"...\",\n",
        "        \"score\": evaluation.get(\"score\"),\n",
        "        \"reason\": evaluation.get(\"reason\"),\n",
        "    })\n",
        "\n",
        "    # # ÊúÄÂàù„ÅÆ1‰ª∂„ÅÆÂá¶ÁêÜ„ÅåÁµÇ„Çè„Å£„Åü„ÅÆ„Åß„ÄÅ„É´„Éº„Éó„ÇíÂº∑Âà∂ÁöÑ„Å´ÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ\n",
        "    # print(\"„ÉÜ„Çπ„Éà„ÅÆ„Åü„ÇÅ„ÄÅÊúÄÂàù„ÅÆ1‰ª∂„ÅßÂá¶ÁêÜ„ÇíÂÅúÊ≠¢„Åó„Åæ„Åô„ÄÇ\")\n",
        "    # break\n",
        "    # -----------------------------------------------\n",
        "\n",
        "# --- DataFrame„Å´„Åó„Å¶‰øùÂ≠ò ---\n",
        "df = pd.DataFrame(evaluated)\n",
        "df.to_json(output_filename, orient=\"records\", force_ascii=False, indent=2)\n",
        "df.to_csv(csv_filename, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"‚úÖ Êé°ÁÇπÁµêÊûú„Çí {csv_filename} „Å® {output_filename} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "\n",
        "# --- Colab„Åß„Çπ„ÇØ„É≠„Éº„É´„Åó„ÇÑ„Åô„ÅèÂÖ®ÊñáË°®Á§∫ ---\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', None)\n",
        "display(df.head(10))"
      ],
      "metadata": {
        "id": "pySpMIFE8BoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##03-3_Â≠¶ÁøíÂæå„ÅÆ„É¢„Éá„É´„ÅÆË©ï‰æ°"
      ],
      "metadata": {
        "id": "oDB_MlOClAnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "TPNh-zeqFJzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "# --- 1. Ê∫ñÂÇô ---\n",
        "\n",
        "# API„Ç≠„Éº„ÅÆË®≠ÂÆö (ÂøÖ„ÅöYOUR_API_KEY„ÅÆÈÉ®ÂàÜ„ÇíÂÆüÈöõ„ÅÆ„Ç≠„Éº„Å´ÁΩÆ„ÅçÊèõ„Åà„Å¶„Åè„Å†„Åï„ÅÑ)\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "judge_model = genai.GenerativeModel('gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "BiAVo2gEhsxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Gemini API Êé•Á∂ö„ÉÜ„Çπ„ÉàÈñãÂßã ---\")\n",
        "\n",
        "# Á∞°Âçò„ÅßÁÑ°ÂÆ≥„Å™„Éó„É≠„É≥„Éó„Éà„ÇíÁî®ÊÑè\n",
        "test_prompt = \"„Åì„Çì„Å´„Å°„ÅØÔºÅLLM„Å´„Å§„ÅÑ„Å¶Á∞°ÊΩî„Å´100ÊñáÂ≠óÁ®ãÂ∫¶„ÅßÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
        "\n",
        "try:\n",
        "    print(\"API„Å´„É™„ÇØ„Ç®„Çπ„Éà„ÇíÈÄÅ‰ø°‰∏≠... („Çø„Ç§„É†„Ç¢„Ç¶„Éà: 60Áßí)\")\n",
        "\n",
        "    # API„ÇíÂëº„Å≥Âá∫„ÅôÈöõ„Å´„ÄÅrequest_options„Åß„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÇíÊåáÂÆö\n",
        "    # ‚òÖ‚òÖ‚òÖ „Åì„Åì„ÅåÈáçË¶Å ‚òÖ‚òÖ‚òÖ\n",
        "    response = judge_model.generate_content(\n",
        "        test_prompt,\n",
        "        request_options={\"timeout\": 60}  # 60Áßí„Åß„Çø„Ç§„É†„Ç¢„Ç¶„Éà\n",
        "    )\n",
        "\n",
        "    print(\"API„Åã„ÇâÂøúÁ≠î„Åå„ÅÇ„Çä„Åæ„Åó„ÅüÔºÅ\")\n",
        "    print(\"-\" * 20)\n",
        "    print(\"ÂøúÁ≠î„ÉÜ„Ç≠„Çπ„Éà:\")\n",
        "    print(response.text)\n",
        "    print(\"-\" * 20)\n",
        "    print(\"‚úÖ „ÉÜ„Çπ„ÉàÊàêÂäü: API„ÅØÊ≠£Â∏∏„Å´Âãï‰Ωú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\")\n",
        "\n",
        "# google.api_core.exceptions.DeadlineExceeded „ÅÆ„Çà„ÅÜ„Å™„Çø„Ç§„É†„Ç¢„Ç¶„ÉàÂõ∫Êúâ„ÅÆ„Ç®„É©„Éº„Çí„Ç≠„É£„ÉÉ„ÉÅ„Åô„Çã„Åì„Å®„ÇÇÂèØËÉΩ\n",
        "except Exception as e:\n",
        "    print(\"\\n‚ùå „ÉÜ„Çπ„ÉàÂ§±Êïó: APIÂëº„Å≥Âá∫„Åó‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "    print(\"--- „Ç®„É©„ÉºË©≥Á¥∞ ---\")\n",
        "    # „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„ÅüÂ†¥Âêà„ÄÅ„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Å´ \"Deadline Exceeded\" „ÇÑ \"Timeout\" „Å®„ÅÑ„Å£„ÅüÊñáË®Ä„ÅåÂê´„Åæ„Çå„Åæ„Åô\n",
        "    print(e)\n",
        "    print(\"--------------------\")\n",
        "    # „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„Åü„Åã„Å©„ÅÜ„Åã„ÇíÂà§ÂÆö„Åô„Çã\n",
        "    if \"deadline\" in str(e).lower() or \"timeout\" in str(e).lower():\n",
        "        print(\"üí° „Éí„É≥„Éà: 60Áßí‰ª•ÂÜÖ„Å´ÂøúÁ≠î„Åå„Å™„Åã„Å£„Åü„Åü„ÇÅ„ÄÅ„Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„ÅüÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Gemini API Êé•Á∂ö„ÉÜ„Çπ„ÉàÁµÇ‰∫Ü ---\")"
      ],
      "metadata": {
        "id": "szg7HPdc9znV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# --- „É¢„Éá„É´Âêç„Éª„Éï„Ç°„Ç§„É´ÂêçË®≠ÂÆö ---\n",
        "date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "input_filename_sft = output_filename_sft\n",
        "output_filename_sft = f\"eval_scored_results_{date_str}.json\"\n",
        "csv_filename_sft = f\"eval_scored_results_{date_str}.csv\"\n",
        "\n",
        "# --- Êé®Ë´ñÁµêÊûú„Çí„É≠„Éº„Éâ ---\n",
        "with open(input_filename_sft, \"r\", encoding=\"utf-8\") as f:\n",
        "    eval_results = json.load(f)\n",
        "\n",
        "evaluated_sft = []\n",
        "\n",
        "# --- Gemini„ÅßÂêÑÂá∫Âäõ„ÇíË©ï‰æ° ---\n",
        "for item in eval_results:\n",
        "    prompt = f\"\"\"\n",
        "„ÅÇ„Å™„Åü„ÅØ„ÄÅÂåªÁôÇ„ÉÜ„Ç≠„Çπ„ÉàÊßãÈÄ†Âåñ„É¢„Éá„É´„ÅÆÂá∫Âäõ„ÇíË©ï‰æ°„Åô„ÇãÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ\n",
        "\n",
        "# ÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà\n",
        "{item[\"input\"]}\n",
        "\n",
        "# „É¢„Éá„É´„ÅÆÂá∫Âäõ\n",
        "{item[\"model_output\"]}\n",
        "\n",
        "Ê¨°„ÅÆ3„Å§„ÅÆË¶≥ÁÇπ„Åã„ÇâË©ï‰æ°„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "1. **ÂΩ¢Âºè„ÅÆÊ≠£Á¢∫ÊÄß**ÔºöÂá∫Âäõ„ÅåÊßãÈÄ†ÂåñÂΩ¢Âºè(JSON)„Å®„Åó„Å¶Â¶•ÂΩì„Åã„ÄÇ\n",
        "2. **ÊÉÖÂ†±„ÅÆÁ∂≤ÁæÖÊÄß**ÔºöÂøÖË¶Å„Å™ÊÉÖÂ†±ÔºàËáìÂô®„ÉªË®∫Êñ≠„ÉªÁóÖÊúü„Å™„Å©Ôºâ„ÇíÂçÅÂàÜ„Å´Âê´„Çì„Åß„ÅÑ„Çã„Åã„ÄÇ\n",
        "3. **ÂÜÖÂÆπ„ÅÆÊ≠£Á¢∫ÊÄß**ÔºöÊäΩÂá∫ÂÜÖÂÆπ„ÅåÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„ÅÆ‰∫ãÂÆü„Å®‰∏ÄËá¥„Åó„Å¶„ÅÑ„Çã„Åã„ÄÇ\n",
        "\n",
        "---\n",
        "\n",
        "Ë©ï‰æ°ÁµêÊûú„ÅØ‰ª•‰∏ã„ÅÆ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Åß„ÄÅÊó•Êú¨Ë™û„ÅßÁ∞°ÊΩî„Å´Âá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "\n",
        "score: <0.0„Äú1.0„ÅÆÊï∞ÂÄ§>\n",
        "ÂΩ¢Âºè„ÅÆÊ≠£Á¢∫ÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "ÊÉÖÂ†±„ÅÆÁ∂≤ÁæÖÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "ÂÜÖÂÆπ„ÅÆÊ≠£Á¢∫ÊÄß: <50ÊñáÂ≠óÁ®ãÂ∫¶„ÅÆË™¨Êòé>\n",
        "Á∑èÂêà„Ç≥„É°„É≥„Éà: <ÂÖ®‰ΩìÁöÑ„Å™Ë©ï‰æ°„Çí‰∏ÄÊñá„Åß„Åæ„Å®„ÇÅ„Çã>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    judge_response = judge_model.generate_content(prompt)\n",
        "    raw_text = judge_response.text.strip()\n",
        "\n",
        "    # --- „Ç≥„Éº„Éâ„Éñ„É≠„ÉÉ„ÇØ„ÇíÈô§ÂéªÔºà```json ... ``` „ÇÑ ``` ... ```Ôºâ---\n",
        "    cleaned_text = re.sub(r\"^```(?:json)?|```$\", \"\", raw_text, flags=re.MULTILINE).strip()\n",
        "\n",
        "    # --- JSON„Éë„Éº„ÇπË©¶Ë°å ---\n",
        "    try:\n",
        "        evaluation = json.loads(cleaned_text)\n",
        "    except json.JSONDecodeError:\n",
        "        # JSON„Å®„Åó„Å¶„Éë„Éº„Çπ„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÄÅ„Çπ„Ç≥„Ç¢„Å†„ÅëÊ≠£Ë¶èË°®Áèæ„ÅßÊäΩÂá∫\n",
        "        score_match = re.search(r'\"?score\"?\\s*[:Ôºö]\\s*([0-9.]+)', cleaned_text)\n",
        "        score = float(score_match.group(1)) if score_match else None\n",
        "        evaluation = {\"score\": score, \"reason\": cleaned_text}\n",
        "\n",
        "    evaluated_sft.append({\n",
        "        \"input\": item[\"input\"][:100] + \"...\",\n",
        "        \"output\": item[\"model_output\"][:150] + \"...\",\n",
        "        \"score\": evaluation.get(\"score\"),\n",
        "        \"reason\": evaluation.get(\"reason\"),\n",
        "    })\n",
        "\n",
        "# --- DataFrame„Å´„Åó„Å¶‰øùÂ≠ò ---\n",
        "df_sft = pd.DataFrame(evaluated_sft)\n",
        "df_sft.to_json(output_filename_sft, orient=\"records\", force_ascii=False, indent=2)\n",
        "df_sft.to_csv(csv_filename_sft, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"‚úÖ Êé°ÁÇπÁµêÊûú„Çí {csv_filename_sft} „Å® {output_filename_sft} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "\n",
        "# --- Colab„Åß„Çπ„ÇØ„É≠„Éº„É´„Åó„ÇÑ„Åô„ÅèÂÖ®ÊñáË°®Á§∫ ---\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', None)\n",
        "display(df_sft.head(10))"
      ],
      "metadata": {
        "id": "1qVOhm93hsxE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
